# üéì Lesson 02: The Brain - ScanEngine Logic

## üõ°Ô∏è Welcome Back, AI-DevSecOps Analyst!

Ready to see how **raw code (human or AI) becomes security violations**? üß† Today we're exploring the **ScanEngine's core logic** - the transformation engine that turns text files into actionable security alerts in our AI-DevSecOps pipeline.

### üéØ What This File Does

The **ScanEngine** (`src/security_py/core/scan_engine.py`) is the **pattern-to-violation converter**. It takes:

```
üìÅ Raw Code File (Human or AI) ‚Üí üîç Pattern Matching ‚Üí üö® SecurityViolation Objects
```

Think of it like an AI-DevSecOps security assembly line:
1. **Input**: A file with code (written by human OR generated by AI)
2. **Process**: Match against security patterns (including AI-specific vulnerabilities)
3. **Output**: Structured violation objects with attribution

### üîç How It Connects to AI-DevSecOps

```
üìÅ Code File (Human or AI) ‚Üí üîç Layer 1: ScanEngine (Creates Violations) ‚Üí üß† EnhancedSecurityValidator (Orchestrates All Layers)
```

The ScanEngine is the **evidence gatherer** for Layer 1 (Deterministic) of our 5-layer security mesh. It finds obvious pattern-based violations, while the other layers handle semantic understanding, operational protection, AI reasoning, and persistence. Without it, the SecurityValidator would have no proof that something is wrong - whether the code came from a human mistake or an AI hallucination!

---

## üìù Code Walkthrough: The Violation Factory

Let's look at the main scanning method:

```typescript
// Lines 120-140: Main Project Scanning
async scanProject(projectPath: string, context: ScanContext): Promise<SecurityViolation[]> {
  const violations: SecurityViolation[] = [];
  
  // For now, we'll simulate scanning files
  // In a real implementation, this would:
  // 1. Read all files in the project
  // 2. Apply each detector to each file
  // 3. Aggregate results
  
  const mockViolations = await this.generateMockViolations(context);
  violations.push(...mockViolations);
  
  return violations;
}
```

### üîç Line-by-Line Explanation

**This code does:**
1. **`const violations: SecurityViolation[] = []`** - Creates an empty array to collect all violations
2. **`mockViolations = await this.generateMockViolations(context)`** - For demo purposes, generates fake violations
3. **`violations.push(...mockViolations)`** - Adds all violations to our collection
4. **`return violations`** - Returns the complete list

### üéØ The Real Magic: Individual File Scanning

```typescript
// Lines 145-165: Individual File Scanning
async scanFile(filePath: string, content: string, context: ScanContext): Promise<SecurityViolation[]> {
  const violations: SecurityViolation[] = [];
  
  // Apply all detectors to the file content
  for (const [category, detector] of this.detectors) {
    const fileViolations = await detector.detect(content, context);
    violations.push(...fileViolations);
  }
  
  return violations;
}
```

**This code does:**
1. **`for (const [category, detector] of this.detectors)`** - Loop through all our detectors (LLM01, LLM06, etc.)
2. **`detector.detect(content, context)`** - Ask each detector to find violations in this file
3. **`violations.push(...fileViolations)`** - Add all found violations to our list
4. **`return violations`** - Return the complete violation list

---

## üè≠ The Detector Factory Line

Each vulnerability type has its own **specialized detector class**:

```typescript
// Lines 200-250: Prompt Injection Detector
class PromptInjectionDetector implements ViolationDetector {
  readonly category = 'LLM01';
  readonly severity = 'HIGH';

  async detect(content: string, context: ScanContext): Promise<SecurityViolation[]> {
    const violations: SecurityViolation[] = [];
    const patterns = OWASP_LLM_PATTERNS.filter(p => p.category === 'LLM01');
    
    for (const pattern of patterns) {
      const matches = content.matchAll(pattern.pattern);
      for (const match of matches) {
        const lines = content.split('\n');
        const lineNumber = lines.findIndex(line => line.includes(match[0])) + 1;
        
        violations.push({
          id: `violation_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
          severity: pattern.severity,
          category: pattern.category,
          title: 'Prompt Injection Vulnerability',
          description: pattern.description,
          file: context.projectPath,
          line: lineNumber,
          codeSnippet: match[0],
          recommendation: pattern.recommendation,
          cweReference: pattern.cweReference,
          agentSource: context.agentSource,
          status: 'OPEN',
          discoveredAt: new Date()
        });
      }
    }
    
    return violations;
  }
}
```

### üîç Violation Object Creation

**This code does:**
1. **`patterns.filter(p => p.category === 'LLM01')`** - Get only LLM01 patterns
2. **`content.matchAll(pattern.pattern)`** - Find all matches in the code
3. **`lines.findIndex(line => line.includes(match[0])) + 1`** - Find the line number
4. **`violations.push({...})`** - Create a complete violation object with ALL details

### üéØ What's in a Violation Object?

Every violation contains:
- **`id`**: Unique identifier (for tracking)
- **`severity`**: CRITICAL/HIGH/MEDIUM/LOW
- **`category`**: LLM01, LLM06, CODING_STANDARDS, etc.
- **`title`**: Human-readable description
- **`file`**: Which file has the problem
- **`line`**: Exact line number
- **`codeSnippet`**: The problematic code
- **`recommendation`**: How to fix it
- **`cweReference`**: Industry standard reference
- **`agentSource`**: Which AI agent wrote this code
- **`status`**: OPEN, IN_PROGRESS, RESOLVED, FALSE_POSITIVE
- **`discoveredAt`**: When we found it

---

## üß™ Manual Verification: Watch the Transformation

Want to see code become violations in real-time? Create this test file:

```python
# test_transformation.py
API_KEY = "sk-1234567890abcdef1234567890abcdef"  # Should trigger LLM06
user_input = input("Enter query: ")
prompt = f"Tell me about {user_input}"  # Should trigger LLM01
```

Now run the scanner to see the transformation:

```bash
python -m security_py test_transformation.py
```

You'll see output like:
```
üîç Scanning: test_transformation.py
üö® LLM06 Critical: Hardcoded API key at line 2
üö® LLM01 High: User input in prompt at line 4
```

### üî¨ Manual Lab: Violation Object Inspector

Let's see exactly what gets created. Create a file called `inspect_violations.py`:

```python
# inspect_violations.py
# This simulates what the ScanEngine creates
import json
from datetime import datetime

mock_violation = {
    "id": "violation_1642781234567_abc123",
    "severity": "CRITICAL",
    "category": "LLM06",
    "title": "Sensitive Information Disclosure",
    "description": "Hardcoded API key detected",
    "file": "test_transformation.py",
    "line": 2,
    "codeSnippet": 'API_KEY = "sk-1234567890abcdef1234567890abcdef"',
    "recommendation": "Move API key to environment variables",
    "cweReference": "CWE-798",
    "agentSource": "windsurf",
    "status": "OPEN",
    "discoveredAt": datetime.now().isoformat()
}

print("üîç Complete Violation Object:")
print(json.dumps(mock_violation, indent=2))
```

Run it with: `python inspect_violations.py`

---

## üéì The Detector Initialization

```typescript
// Lines 85-95: Detector Setup
private initializeDetectors(): void {
  // Initialize OWASP LLM detectors
  this.detectors.set('LLM01', new PromptInjectionDetector());
  this.detectors.set('LLM02', new InsecureOutputDetector());
  this.detectors.set('LLM06', new SensitiveInfoDetector());
  this.detectors.set('CODING_STANDARDS', new CodingStandardsDetector());
}
```

**This code does:**
1. **`this.detectors.set('LLM01', new PromptInjectionDetector())`** - Create a detector for each category
2. **Store in Map** - So we can quickly look up detectors by category
3. **Ready for scanning** - All detectors are initialized and waiting

---

## üìö AI-DevSecOps Interview Prep

**Q: Why create separate detector classes instead of one big scanning function in AI-DevSecOps?**

**A**: Separation of concerns and maintainability - crucial when dealing with AI-generated code. Each detector knows its patterns and logic best. If we need to improve LLM01 detection for AI prompt injection, we only touch the PromptInjectionDetector. It also makes testing easier - we can test each detector in isolation against known AI vulnerability patterns.

**Q: What's the purpose of the `ScanContext` parameter in AI-DevSecOps?**

**A**: Context provides metadata about the scan - which project, which phase (WINDSURF/ANTI_GRAVITY), which developer, and **which AI agent generated the code**. This helps with AI-specific prioritization and audit trails. We can track if Windsurf tends to generate more LLM01 violations than Anti-Gravity, for example.

**Q: How does the ScanEngine handle false positives in AI-DevSecOps?**

**A**: The ScanEngine flags potential violations based on patterns. False positives are handled later in the workflow - developers can mark violations as FALSE_POSITIVE, which updates the status but keeps the original detection in the audit log. In AI-DevSecOps, this is crucial because AI agents might generate code that looks suspicious but is actually safe.

**Q: Why generate unique IDs for violations in AI-DevSecOps?**

**A**: For tracking and reference, especially important with AI-generated code. If a developer overrides a violation from an AI agent, we need to know exactly which one they're talking about. The ID also helps with AI-specific audit trails and reporting - we can analyze which AI agent tends to generate which types of violations.

---

## üéØ Check for Understanding

**Question**: Look at the violation object creation code. Why do we include both `codeSnippet` AND `file` + `line`? Wouldn't one be enough?

*Hint: Think about a developer who gets an alert - what information do they need to fix the problem quickly?*

---

## üöÄ Ready for Lesson 03?

Next up, we'll explore the **SecurityValidator** - the "brain" that orchestrates all 5 layers of our security mesh and decides whether to block deployment. Get ready to see the Hard Guardrail in action! üß†

Then in Lessons 06-08, you'll master the **advanced layers** that go beyond pattern matching:
- **Lesson 06**: Semantic Analysis - Code mind reading with AST
- **Lesson 07**: Policy Engine - Business compliance enforcement  
- **Lesson 08**: Shell Operations - Operational guardrails

*Remember: Good security analysts understand how evidence becomes enforcement across all layers!* üõ°Ô∏è
